from itertools import chain, combinations
from os.path import join
import glob
import re
from collections import defaultdict
import os
from os.path import join
import glob
from riboraptor.helpers import mkdir_p
import numpy as np
import pandas as pd

include:
    config['config_path']

workdir: OUT_DIR


mkdir_p(join(OUT_DIR, 'slurm-logs'))
ALL_SRA_FILES = glob.glob('{}/**/*.sra'.format(RAWDATA_DIR), recursive=True)
SRX_ID = defaultdict(list)

for sample in ALL_SRA_FILES:
    srx, srr = sample.replace('{}'.format(RAWDATA_DIR),'').lstrip('/').rstrip('/').split('/')
    SRX_ID[srx].append(srr.replace('.sra', ''))

SRR_ID = list(SRX_ID.values())
SRX_SAMPLES = list(SRX_ID.keys())

ALL_SRR = [item for sublist in SRR_ID for item in sublist]


def merge_fastq_input(wildcards):
    return ['sratofastq/{}.fastq.gz'.format(srr) for srr in SRX_ID[wildcards.sample]]


def sra_to_fastq_input(wildcards):
    srr_id = wildcards.sample
    for srx_id in list(SRX_ID.keys()):
        value = SRX_ID[srx_id]
        if srr_id in list(value):
            return ancient(str(join(RAWDATA_DIR, srx_id, srr_id+'.sra')))
    print("WRONG encodeterend: {}".format(srr_id))

def get_wrapper(wrapper_name):
    path = os.path.dirname(os.path.abspath(os.path.realpath(workflow.snakefile)))
    return 'file://' + os.path.join(path,
                                    'wrappers',
                                    wrapper_name + '.py')


rule all:
    input:
        CDNA_IDX,
        expand('counts/{sample}/abundance.tsv', sample=SRX_SAMPLES)

rule create_index:
    input: CDNA_FA_GZ
    output: CDNA_IDX
    shell:
        '''kallisto index -i {output} {input}'''

"""
rule sra_to_fastq:
    input: sra_to_fastq_input
    benchmark: 'benchmarks/sra_to_fastq/{sample}.txt'
    output: 'sratofastq/{sample}.fastq.gz'
    params:
        prefix_sra='sratofastq/{sample}.sra.fastq',
        prefix='sratofastq/{sample}.fastq',
        temp_dir='/tmp/{sample}_sratofastq',
    shell:
        r'''
        fastq-dump --split-3 \
        -O sratofastq {input} \
        && gzip {params.prefix}
        '''
"""

rule sra_to_fastq:
    input: sra_to_fastq_input
    benchmark: 'benchmarks/sra_to_fastq/{sample}.txt'
    output: 'sratofastq/{sample}_1.fastq.gz'
    params:
        prefix_sra='sratofastq/{sample}.sra.fastq',
        prefix='sratofastq/{sample}.fastq',
        temp_dir='/tmp/{sample}_sratofastq',
    threads: 16
    shell:
        r'''
        parallel-fastq-dump --threads 16 --outdir sratofastq/ --split-files --gzip -s {input}
        '''

rule merge_fastq:
    input:
        all_fastq = expand('sratofastq/{srr}_1.fastq.gz', srr=ALL_SRR),
        dynamic_input = merge_fastq_input
    benchmark: 'benchmarks/merge_fastq/{sample}.txt'
    output: temp('fastq_merged/{sample}.fastq.gz')
    wrapper:
        get_wrapper('merge_fastq_wrapper')

rule quantify:
    input:
        R1='fastq_merged/{sample}.fastq.gz',
    output:
        'counts/{sample}/abundance.tsv',
    params:
        index=CDNA_IDX,
        outdir='counts/{sample}'
    threads: 16 ## hardcoded below
    shell:
        r'''
        kallisto quant \
        --index={params.index} \
        --threads={threads}\
        -l 200 \
        -s 30 \
        --output-dir={params.outdir} \
        --single \
        -b 100 <(zcat {input.R1})'''
