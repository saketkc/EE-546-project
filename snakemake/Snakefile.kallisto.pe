from itertools import chain, combinations
from os.path import join
import glob
import re
from collections import defaultdict
import os
from os.path import join
import glob
from riboraptor.helpers import mkdir_p
import numpy as np
import pandas as pd

include:
    config['config_path']

workdir: OUT_DIR


mkdir_p(join(OUT_DIR, 'slurm-logs'))
ALL_SRA_FILES = glob.glob('{}/**/*.sra'.format(RAWDATA_DIR), recursive=True)
SRX_ID = defaultdict(list)

for sample in ALL_SRA_FILES:
    srx, srr = sample.replace('{}'.format(RAWDATA_DIR),'').lstrip('/').rstrip('/').split('/')
    SRX_ID[srx].append(srr.replace('.sra', ''))

SRR_ID = list(SRX_ID.values())
SRX_SAMPLES = list(SRX_ID.keys())

ALL_SRR = [item for sublist in SRR_ID for item in sublist]


def merge_fastq_input1(wildcards):
    return ['sratofastq/{}_1.fastq.gz'.format(srr) for srr in SRX_ID[wildcards.sample]]

def merge_fastq_input2(wildcards):
    return ['sratofastq/{}_2.fastq.gz'.format(srr) for srr in SRX_ID[wildcards.sample]]

def sra_to_fastq_input(wildcards):
    srr_id = wildcards.sample
    for srx_id in list(SRX_ID.keys()):
        value = SRX_ID[srx_id]
        if srr_id in list(value):
            return ancient(str(join(RAWDATA_DIR, srx_id, srr_id+'.sra')))
    print("WRONG encodeterend: {}".format(srr_id))

def get_wrapper(wrapper_name):
    path = os.path.dirname(os.path.abspath(os.path.realpath(workflow.snakefile)))
    return 'file://' + os.path.join(path,
                                    'wrappers',
                                    wrapper_name + '.py')


rule all:
    input:
        CDNA_IDX,
        expand('counts/{sample}/abundance.tsv', sample=SRX_SAMPLES)

rule create_index:
    input: CDNA_FA_GZ
    output: CDNA_IDX
    shell:
        '''kallisto index -i {output} {input}'''
"""
rule sra_to_fastq:
    input: sra_to_fastq_input
    benchmark: 'benchmarks/sra_to_fastq/{sample}.txt'
    output:
        R1=temp('sratofastq/{sample}_1.fastq.gz'),
        R2=temp('sratofastq/{sample}_2.fastq.gz')
    params:
        prefix_sra='sratofastq/{sample}.sra.fastq',
        prefix1='sratofastq/{sample}_1.fastq',
        prefix2='sratofastq/{sample}_2.fastq',
        temp_dir='/tmp/{sample}_sratofastq',
    shell:
        r'''
        fastq-dump --split-3 \
        -O sratofastq {input} \
        && gzip {params.prefix1} \
        && gzip {params.prefix2}
        '''
"""
rule sra_to_fastq:
    input: sra_to_fastq_input
    benchmark: 'benchmarks/sra_to_fastq/{sample}.txt'
    output:
        R1=temp('sratofastq/{sample}_1.fastq.gz'),
        R2=temp('sratofastq/{sample}_2.fastq.gz')
    params:
        prefix_sra='sratofastq/{sample}.sra.fastq',
        prefix1='sratofastq/{sample}_1.fastq',
        prefix2='sratofastq/{sample}_2.fastq',
        temp_dir='/tmp/{sample}_sratofastq',
        sample='{sample}',
    threads: 16
    shell:
        r'''
        parallel-fastq-dump --threads 16 --outdir sratofastq/ --split-files --gzip -s {input}
        '''


rule merge_fastq_R1:
    input:
        all_fastq = expand('sratofastq/{srr}_1.fastq.gz', srr=ALL_SRR),
        dynamic_input = merge_fastq_input1
    benchmark: 'benchmarks/merge_fastq/{sample}.txt'
    output: temp('fastq_merged/{sample}_R1.fastq.gz')
    wrapper:
        get_wrapper('merge_fastq_wrapper')

rule merge_fastq_R2:
    input:
        all_fastq = expand('sratofastq/{srr}_2.fastq.gz', srr=ALL_SRR),
        dynamic_input = merge_fastq_input2
    benchmark: 'benchmarks/merge_fastq/{sample}.txt'
    output: temp('fastq_merged/{sample}_R2.fastq.gz')
    wrapper:
        get_wrapper('merge_fastq_wrapper')

rule quantify:
    input:
        R1='fastq_merged/{sample}_R1.fastq.gz',
        R2='fastq_merged/{sample}_R2.fastq.gz'
    output:
        'counts/{sample}/abundance.tsv',
    params:
        index=CDNA_IDX,
        outdir='counts/{sample}'
    threads: 16
    shell:
        r'''
        kallisto quant \
        --index={params.index} \
        --threads={threads}\
        --output-dir={params.outdir} \
        -b 100 <(zcat {input.R1}) <(zcat {input.R2})'''
