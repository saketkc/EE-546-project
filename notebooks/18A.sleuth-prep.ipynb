{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppressMessages({\n",
    "  library(\"sleuth\")\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<table width=\"100%\" summary=\"page for sleuth_prep {sleuth}\"><tr><td>sleuth_prep {sleuth}</td><td style=\"text-align: right;\">R Documentation</td></tr></table>\n",
       "\n",
       "<h2>Constructor for a 'sleuth' object</h2>\n",
       "\n",
       "<h3>Description</h3>\n",
       "\n",
       "<p>A sleuth is a group of kallistos. Borrowing this terminology, a 'sleuth' object stores\n",
       "a group of kallisto results, and can then operate on them while\n",
       "accounting for covariates, sequencing depth, technical and biological\n",
       "variance.\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Usage</h3>\n",
       "\n",
       "<pre>\n",
       "sleuth_prep(sample_to_covariates, full_model = NULL, target_mapping = NULL,\n",
       "  aggregation_column = NULL, num_cores = max(1L, parallel::detectCores() -\n",
       "  1L), ...)\n",
       "</pre>\n",
       "\n",
       "\n",
       "<h3>Arguments</h3>\n",
       "\n",
       "<table summary=\"R argblock\">\n",
       "<tr valign=\"top\"><td><code>sample_to_covariates</code></td>\n",
       "<td>\n",
       "<p>a <code>data.frame</code> which contains a mapping\n",
       "from <code>sample</code> (a required column) to some set of experimental conditions or\n",
       "covariates. The column <code>path</code> is also required, which is a character\n",
       "vector where each element points to the corresponding kallisto output directory. The column\n",
       "<code>sample</code> should be in the same order as the corresponding entry in\n",
       "<code>path</code>.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>full_model</code></td>\n",
       "<td>\n",
       "<p>an R <code>formula</code> which explains the full model (design)\n",
       "of the experiment OR a design matrix. It must be consistent with the data.frame supplied in\n",
       "<code>sample_to_covariates</code>. You can fit multiple covariates by joining them with '+' (see example)</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>target_mapping</code></td>\n",
       "<td>\n",
       "<p>a <code>data.frame</code> that has at least one column\n",
       "'target_id' and others that denote the mapping for each target. if it is not\n",
       "<code>NULL</code>, <code>target_mapping</code> is joined with many outputs where it\n",
       "might be useful. For example, you might have columns 'target_id',\n",
       "'ensembl_gene' and 'entrez_gene' to denote different transcript to gene\n",
       "mappings. Note that sleuth_prep will treat all columns as having the 'character' data type.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>aggregation_column</code></td>\n",
       "<td>\n",
       "<p>a string of the column name in <code>target_mapping</code> to aggregate targets\n",
       "(typically to summarize the data on the gene level). The aggregation is done using a p-value aggregation\n",
       "method when generating the results table. See <code>sleuth_results</code> for more information.</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>num_cores</code></td>\n",
       "<td>\n",
       "<p>an integer of the number of computer cores mclapply should use\n",
       "to speed up sleuth preparation</p>\n",
       "</td></tr>\n",
       "<tr valign=\"top\"><td><code>...</code></td>\n",
       "<td>\n",
       "<p>any of several other arguments that can be used as advanced options for\n",
       "sleuth preparation. See details.</p>\n",
       "</td></tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "<h3>Details</h3>\n",
       "\n",
       "<p>This method takes a list of samples with kallisto results and returns a sleuth\n",
       "object with the defined normalization of the data across samples (default is the DESeq method;\n",
       "See <code>basic_filter</code>), and then the defined transformation of the data (default is log(x + 0.5)).\n",
       "This also collects all of the bootstraps for the modeling done using <code>sleuth_fit</code>. This\n",
       "function also takes several advanced options that can be used to customize your analysis.\n",
       "Here are the advanced options for <code>sleuth_prep</code>:\n",
       "</p>\n",
       "<p>Extra arguments related to Bootstrap Summarizing:\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li> <p><code>extra_bootstrap_summary</code>: if <code>TRUE</code>, compute extra summary\n",
       "statistics for estimated counts. This is not necessary for typical analyses; it is only needed\n",
       "for certain plots (e.g. <code>plot_bootstrap</code>). Default is <code>FALSE</code>.\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><code>read_bootstrap_tpm</code>: read and compute summary statistics on bootstraps on the TPM.\n",
       "This is not necessary for typical analyses; it is only needed for some plots (e.g. <code>plot_bootstrap</code>)\n",
       "and if TPM values are used for <code>sleuth_fit</code>. Default is <code>FALSE</code>.\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><code>max_bootstrap</code>: the maximum number of bootstrap values to read for each\n",
       "transcript. Setting this lower than the total bootstraps available will save some time, but\n",
       "will likely decrease the accuracy of the estimation of the inferential noise.\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "<p>Advanced Options for Filtering:\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li> <p><code>filter_fun</code>: the function to use when filtering. This function will be applied to the raw counts\n",
       "on a row-wise basis, meaning that each feature will be considered individually. The default is to filter out\n",
       "any features that do not have at least 5 estimated counts in at least 47\n",
       "for more information). If the preferred filtering method requires a matrix-wide transformation or otherwise\n",
       "needs to consider multiple features simultaneously instead of independently, please consider using\n",
       "<code>filter_target_id</code> below.\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><code>filter_target_id</code>: character vector of target_ids to filter using methods that\n",
       "can't be implemented using <code>filter_fun</code>. If non-NULL, this will override <code>filter_fun</code>.\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "<p>Advanced Options for the Normalization Step:\n",
       "(NOTE: Be sure you know what you're doing before you use these options)\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li> <p><code>normalize</code>: boolean for whether normalization and other steps should be performed.\n",
       "If this is set to false, bootstraps will not be read and transformation of the data will not be done.\n",
       "This should only be set to <code>FALSE</code> if one desires to do a quick check of the raw data.\n",
       "The default is <code>TRUE</code>.\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><code>norm_fun_counts</code>: a function to perform between sample normalization on the estimated counts.\n",
       "The default is the DESeq method. See <code>norm_factors</code> for details.\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><code>norm_fun_tpm</code>: a function to perform between sample normalization on the TPM.\n",
       "The default is the DESeq method. See <code>norm_factors</code> for details.\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "<p>Advanced Options for the Transformation Step:\n",
       "(NOTE: Be sure you know what you're doing before you use these options)\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li> <p><code>transform_fun_counts</code>: the transformation that should be applied\n",
       "to the normalized counts. Default is <code>'log(x+0.5)'</code> (i.e. natural log with 0.5 offset).\n",
       "</p>\n",
       "</li>\n",
       "<li> <p><code>transform_fun_tpm</code>: the transformation that should be applied\n",
       "to the TPM values. Default is <code>'x'</code> (i.e. the identity function / no transformation)\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "<p>Advanced Options for Gene Aggregation:\n",
       "</p>\n",
       "\n",
       "<ul>\n",
       "<li> <p><code>gene_mode</code>: Set this to <code>TRUE</code> to get the old counts-aggregation method\n",
       "for doing gene-level analysis. This requires <code>aggregation_column</code> to be set. If \n",
       "<code>TRUE</code>, this will override the p-value aggregation mode, but will allow for gene-centric\n",
       "modeling, plotting, and results.\n",
       "</p>\n",
       "</li></ul>\n",
       "\n",
       "\n",
       "\n",
       "<h3>Value</h3>\n",
       "\n",
       "<p>a <code>sleuth</code> object containing all kallisto samples, metadata,\n",
       "and summary statistics\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>See Also</h3>\n",
       "\n",
       "<p><code>sleuth_fit</code> to fit a model, <code>sleuth_wt</code> or\n",
       "<code>sleuth_lrt</code> to perform hypothesis testing\n",
       "</p>\n",
       "\n",
       "\n",
       "<h3>Examples</h3>\n",
       "\n",
       "<pre>\n",
       "# Assume we have run kallisto on a set of samples, and have two treatments,\n",
       "genotype and drug.\n",
       "colnames(s2c)\n",
       "# [1] \"sample\"  \"genotype\"  \"drug\"  \"path\"\n",
       "so &lt;- sleuth_prep(s2c, ~genotype + drug)\n",
       "</pre>\n",
       "\n",
       "<hr /><div style=\"text-align: center;\">[Package <em>sleuth</em> version 0.30.0 ]</div>"
      ],
      "text/latex": [
       "\\inputencoding{utf8}\n",
       "\\HeaderA{sleuth\\_prep}{Constructor for a 'sleuth' object}{sleuth.Rul.prep}\n",
       "%\n",
       "\\begin{Description}\\relax\n",
       "A sleuth is a group of kallistos. Borrowing this terminology, a 'sleuth' object stores\n",
       "a group of kallisto results, and can then operate on them while\n",
       "accounting for covariates, sequencing depth, technical and biological\n",
       "variance.\n",
       "\\end{Description}\n",
       "%\n",
       "\\begin{Usage}\n",
       "\\begin{verbatim}\n",
       "sleuth_prep(sample_to_covariates, full_model = NULL, target_mapping = NULL,\n",
       "  aggregation_column = NULL, num_cores = max(1L, parallel::detectCores() -\n",
       "  1L), ...)\n",
       "\\end{verbatim}\n",
       "\\end{Usage}\n",
       "%\n",
       "\\begin{Arguments}\n",
       "\\begin{ldescription}\n",
       "\\item[\\code{sample\\_to\\_covariates}] a \\code{data.frame} which contains a mapping\n",
       "from \\code{sample} (a required column) to some set of experimental conditions or\n",
       "covariates. The column \\code{path} is also required, which is a character\n",
       "vector where each element points to the corresponding kallisto output directory. The column\n",
       "\\code{sample} should be in the same order as the corresponding entry in\n",
       "\\code{path}.\n",
       "\n",
       "\\item[\\code{full\\_model}] an R \\code{formula} which explains the full model (design)\n",
       "of the experiment OR a design matrix. It must be consistent with the data.frame supplied in\n",
       "\\code{sample\\_to\\_covariates}. You can fit multiple covariates by joining them with '+' (see example)\n",
       "\n",
       "\\item[\\code{target\\_mapping}] a \\code{data.frame} that has at least one column\n",
       "'target\\_id' and others that denote the mapping for each target. if it is not\n",
       "\\code{NULL}, \\code{target\\_mapping} is joined with many outputs where it\n",
       "might be useful. For example, you might have columns 'target\\_id',\n",
       "'ensembl\\_gene' and 'entrez\\_gene' to denote different transcript to gene\n",
       "mappings. Note that sleuth\\_prep will treat all columns as having the 'character' data type.\n",
       "\n",
       "\\item[\\code{aggregation\\_column}] a string of the column name in \\code{\\LinkA{target\\_mapping}{target.Rul.mapping}} to aggregate targets\n",
       "(typically to summarize the data on the gene level). The aggregation is done using a p-value aggregation\n",
       "method when generating the results table. See \\code{\\LinkA{sleuth\\_results}{sleuth.Rul.results}} for more information.\n",
       "\n",
       "\\item[\\code{num\\_cores}] an integer of the number of computer cores mclapply should use\n",
       "to speed up sleuth preparation\n",
       "\n",
       "\\item[\\code{...}] any of several other arguments that can be used as advanced options for\n",
       "sleuth preparation. See details.\n",
       "\\end{ldescription}\n",
       "\\end{Arguments}\n",
       "%\n",
       "\\begin{Details}\\relax\n",
       "This method takes a list of samples with kallisto results and returns a sleuth\n",
       "object with the defined normalization of the data across samples (default is the DESeq method;\n",
       "See \\code{\\LinkA{basic\\_filter}{basic.Rul.filter}}), and then the defined transformation of the data (default is log(x + 0.5)).\n",
       "This also collects all of the bootstraps for the modeling done using \\code{\\LinkA{sleuth\\_fit}{sleuth.Rul.fit}}. This\n",
       "function also takes several advanced options that can be used to customize your analysis.\n",
       "Here are the advanced options for \\code{sleuth\\_prep}:\n",
       "\n",
       "Extra arguments related to Bootstrap Summarizing:\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item \\code{extra\\_bootstrap\\_summary}: if \\code{TRUE}, compute extra summary\n",
       "statistics for estimated counts. This is not necessary for typical analyses; it is only needed\n",
       "for certain plots (e.g. \\code{\\LinkA{plot\\_bootstrap}{plot.Rul.bootstrap}}). Default is \\code{FALSE}.\n",
       "\\item \\code{read\\_bootstrap\\_tpm}: read and compute summary statistics on bootstraps on the TPM.\n",
       "This is not necessary for typical analyses; it is only needed for some plots (e.g. \\code{\\LinkA{plot\\_bootstrap}{plot.Rul.bootstrap}})\n",
       "and if TPM values are used for \\code{\\LinkA{sleuth\\_fit}{sleuth.Rul.fit}}. Default is \\code{FALSE}.\n",
       "\\item \\code{max\\_bootstrap}: the maximum number of bootstrap values to read for each\n",
       "transcript. Setting this lower than the total bootstraps available will save some time, but\n",
       "will likely decrease the accuracy of the estimation of the inferential noise.\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\n",
       "Advanced Options for Filtering:\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item \\code{filter\\_fun}: the function to use when filtering. This function will be applied to the raw counts\n",
       "on a row-wise basis, meaning that each feature will be considered individually. The default is to filter out\n",
       "any features that do not have at least 5 estimated counts in at least 47\n",
       "for more information). If the preferred filtering method requires a matrix-wide transformation or otherwise\n",
       "needs to consider multiple features simultaneously instead of independently, please consider using\n",
       "\\code{filter\\_target\\_id} below.\n",
       "\\item \\code{filter\\_target\\_id}: character vector of target\\_ids to filter using methods that\n",
       "can't be implemented using \\code{filter\\_fun}. If non-NULL, this will override \\code{filter\\_fun}.\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\n",
       "Advanced Options for the Normalization Step:\n",
       "(NOTE: Be sure you know what you're doing before you use these options)\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item \\code{normalize}: boolean for whether normalization and other steps should be performed.\n",
       "If this is set to false, bootstraps will not be read and transformation of the data will not be done.\n",
       "This should only be set to \\code{FALSE} if one desires to do a quick check of the raw data.\n",
       "The default is \\code{TRUE}.\n",
       "\\item \\code{norm\\_fun\\_counts}: a function to perform between sample normalization on the estimated counts.\n",
       "The default is the DESeq method. See \\code{\\LinkA{norm\\_factors}{norm.Rul.factors}} for details.\n",
       "\\item \\code{norm\\_fun\\_tpm}: a function to perform between sample normalization on the TPM.\n",
       "The default is the DESeq method. See \\code{\\LinkA{norm\\_factors}{norm.Rul.factors}} for details.\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\n",
       "Advanced Options for the Transformation Step:\n",
       "(NOTE: Be sure you know what you're doing before you use these options)\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item \\code{transform\\_fun\\_counts}: the transformation that should be applied\n",
       "to the normalized counts. Default is \\code{'log(x+0.5)'} (i.e. natural log with 0.5 offset).\n",
       "\\item \\code{transform\\_fun\\_tpm}: the transformation that should be applied\n",
       "to the TPM values. Default is \\code{'x'} (i.e. the identity function / no transformation)\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\n",
       "Advanced Options for Gene Aggregation:\n",
       "\\begin{itemize}\n",
       "\n",
       "\\item \\code{gene\\_mode}: Set this to \\code{TRUE} to get the old counts-aggregation method\n",
       "for doing gene-level analysis. This requires \\code{aggregation\\_column} to be set. If \n",
       "\\code{TRUE}, this will override the p-value aggregation mode, but will allow for gene-centric\n",
       "modeling, plotting, and results.\n",
       "\n",
       "\\end{itemize}\n",
       "\n",
       "\\end{Details}\n",
       "%\n",
       "\\begin{Value}\n",
       "a \\code{sleuth} object containing all kallisto samples, metadata,\n",
       "and summary statistics\n",
       "\\end{Value}\n",
       "%\n",
       "\\begin{SeeAlso}\\relax\n",
       "\\code{\\LinkA{sleuth\\_fit}{sleuth.Rul.fit}} to fit a model, \\code{\\LinkA{sleuth\\_wt}{sleuth.Rul.wt}} or\n",
       "\\code{\\LinkA{sleuth\\_lrt}{sleuth.Rul.lrt}} to perform hypothesis testing\n",
       "\\end{SeeAlso}\n",
       "%\n",
       "\\begin{Examples}\n",
       "\\begin{ExampleCode}\n",
       "# Assume we have run kallisto on a set of samples, and have two treatments,\n",
       "genotype and drug.\n",
       "colnames(s2c)\n",
       "# [1] \"sample\"  \"genotype\"  \"drug\"  \"path\"\n",
       "so <- sleuth_prep(s2c, ~genotype + drug)\n",
       "\\end{ExampleCode}\n",
       "\\end{Examples}"
      ],
      "text/plain": [
       "sleuth_prep               package:sleuth               R Documentation\n",
       "\n",
       "_\bC_\bo_\bn_\bs_\bt_\br_\bu_\bc_\bt_\bo_\br _\bf_\bo_\br _\ba '_\bs_\bl_\be_\bu_\bt_\bh' _\bo_\bb_\bj_\be_\bc_\bt\n",
       "\n",
       "_\bD_\be_\bs_\bc_\br_\bi_\bp_\bt_\bi_\bo_\bn:\n",
       "\n",
       "     A sleuth is a group of kallistos. Borrowing this terminology, a\n",
       "     'sleuth' object stores a group of kallisto results, and can then\n",
       "     operate on them while accounting for covariates, sequencing depth,\n",
       "     technical and biological variance.\n",
       "\n",
       "_\bU_\bs_\ba_\bg_\be:\n",
       "\n",
       "     sleuth_prep(sample_to_covariates, full_model = NULL, target_mapping = NULL,\n",
       "       aggregation_column = NULL, num_cores = max(1L, parallel::detectCores() -\n",
       "       1L), ...)\n",
       "     \n",
       "_\bA_\br_\bg_\bu_\bm_\be_\bn_\bt_\bs:\n",
       "\n",
       "sample_to_covariates: a ‘data.frame’ which contains a mapping from\n",
       "          ‘sample’ (a required column) to some set of experimental\n",
       "          conditions or covariates. The column ‘path’ is also required,\n",
       "          which is a character vector where each element points to the\n",
       "          corresponding kallisto output directory. The column ‘sample’\n",
       "          should be in the same order as the corresponding entry in\n",
       "          ‘path’.\n",
       "\n",
       "full_model: an R ‘formula’ which explains the full model (design) of\n",
       "          the experiment OR a design matrix. It must be consistent with\n",
       "          the data.frame supplied in ‘sample_to_covariates’. You can\n",
       "          fit multiple covariates by joining them with '+' (see\n",
       "          example)\n",
       "\n",
       "target_mapping: a ‘data.frame’ that has at least one column 'target_id'\n",
       "          and others that denote the mapping for each target. if it is\n",
       "          not ‘NULL’, ‘target_mapping’ is joined with many outputs\n",
       "          where it might be useful. For example, you might have columns\n",
       "          'target_id', 'ensembl_gene' and 'entrez_gene' to denote\n",
       "          different transcript to gene mappings. Note that sleuth_prep\n",
       "          will treat all columns as having the 'character' data type.\n",
       "\n",
       "aggregation_column: a string of the column name in ‘target_mapping’ to\n",
       "          aggregate targets (typically to summarize the data on the\n",
       "          gene level). The aggregation is done using a p-value\n",
       "          aggregation method when generating the results table. See\n",
       "          ‘sleuth_results’ for more information.\n",
       "\n",
       "num_cores: an integer of the number of computer cores mclapply should\n",
       "          use to speed up sleuth preparation\n",
       "\n",
       "     ...: any of several other arguments that can be used as advanced\n",
       "          options for sleuth preparation. See details.\n",
       "\n",
       "_\bD_\be_\bt_\ba_\bi_\bl_\bs:\n",
       "\n",
       "     This method takes a list of samples with kallisto results and\n",
       "     returns a sleuth object with the defined normalization of the data\n",
       "     across samples (default is the DESeq method; See ‘basic_filter’),\n",
       "     and then the defined transformation of the data (default is log(x\n",
       "     + 0.5)).  This also collects all of the bootstraps for the\n",
       "     modeling done using ‘sleuth_fit’. This function also takes several\n",
       "     advanced options that can be used to customize your analysis.\n",
       "     Here are the advanced options for ‘sleuth_prep’:\n",
       "\n",
       "     Extra arguments related to Bootstrap Summarizing:\n",
       "\n",
       "        • ‘extra_bootstrap_summary’: if ‘TRUE’, compute extra summary\n",
       "          statistics for estimated counts. This is not necessary for\n",
       "          typical analyses; it is only needed for certain plots (e.g.\n",
       "          ‘plot_bootstrap’). Default is ‘FALSE’.\n",
       "\n",
       "        • ‘read_bootstrap_tpm’: read and compute summary statistics on\n",
       "          bootstraps on the TPM.  This is not necessary for typical\n",
       "          analyses; it is only needed for some plots (e.g.\n",
       "          ‘plot_bootstrap’) and if TPM values are used for\n",
       "          ‘sleuth_fit’. Default is ‘FALSE’.\n",
       "\n",
       "        • ‘max_bootstrap’: the maximum number of bootstrap values to\n",
       "          read for each transcript. Setting this lower than the total\n",
       "          bootstraps available will save some time, but will likely\n",
       "          decrease the accuracy of the estimation of the inferential\n",
       "          noise.\n",
       "\n",
       "     Advanced Options for Filtering:\n",
       "\n",
       "        • ‘filter_fun’: the function to use when filtering. This\n",
       "          function will be applied to the raw counts on a row-wise\n",
       "          basis, meaning that each feature will be considered\n",
       "          individually. The default is to filter out any features that\n",
       "          do not have at least 5 estimated counts in at least 47 for\n",
       "          more information). If the preferred filtering method requires\n",
       "          a matrix-wide transformation or otherwise needs to consider\n",
       "          multiple features simultaneously instead of independently,\n",
       "          please consider using ‘filter_target_id’ below.\n",
       "\n",
       "        • ‘filter_target_id’: character vector of target_ids to filter\n",
       "          using methods that can't be implemented using ‘filter_fun’.\n",
       "          If non-NULL, this will override ‘filter_fun’.\n",
       "\n",
       "     Advanced Options for the Normalization Step: (NOTE: Be sure you\n",
       "     know what you're doing before you use these options)\n",
       "\n",
       "        • ‘normalize’: boolean for whether normalization and other\n",
       "          steps should be performed.  If this is set to false,\n",
       "          bootstraps will not be read and transformation of the data\n",
       "          will not be done.  This should only be set to ‘FALSE’ if one\n",
       "          desires to do a quick check of the raw data.  The default is\n",
       "          ‘TRUE’.\n",
       "\n",
       "        • ‘norm_fun_counts’: a function to perform between sample\n",
       "          normalization on the estimated counts.  The default is the\n",
       "          DESeq method. See ‘norm_factors’ for details.\n",
       "\n",
       "        • ‘norm_fun_tpm’: a function to perform between sample\n",
       "          normalization on the TPM.  The default is the DESeq method.\n",
       "          See ‘norm_factors’ for details.\n",
       "\n",
       "     Advanced Options for the Transformation Step: (NOTE: Be sure you\n",
       "     know what you're doing before you use these options)\n",
       "\n",
       "        • ‘transform_fun_counts’: the transformation that should be\n",
       "          applied to the normalized counts. Default is ‘'log(x+0.5)'’\n",
       "          (i.e. natural log with 0.5 offset).\n",
       "\n",
       "        • ‘transform_fun_tpm’: the transformation that should be\n",
       "          applied to the TPM values. Default is ‘'x'’ (i.e. the\n",
       "          identity function / no transformation)\n",
       "\n",
       "     Advanced Options for Gene Aggregation:\n",
       "\n",
       "        • ‘gene_mode’: Set this to ‘TRUE’ to get the old\n",
       "          counts-aggregation method for doing gene-level analysis. This\n",
       "          requires ‘aggregation_column’ to be set. If ‘TRUE’, this will\n",
       "          override the p-value aggregation mode, but will allow for\n",
       "          gene-centric modeling, plotting, and results.\n",
       "\n",
       "_\bV_\ba_\bl_\bu_\be:\n",
       "\n",
       "     a ‘sleuth’ object containing all kallisto samples, metadata, and\n",
       "     summary statistics\n",
       "\n",
       "_\bS_\be_\be _\bA_\bl_\bs_\bo:\n",
       "\n",
       "     ‘sleuth_fit’ to fit a model, ‘sleuth_wt’ or ‘sleuth_lrt’ to\n",
       "     perform hypothesis testing\n",
       "\n",
       "_\bE_\bx_\ba_\bm_\bp_\bl_\be_\bs:\n",
       "\n",
       "     # Assume we have run kallisto on a set of samples, and have two treatments,\n",
       "     genotype and drug.\n",
       "     colnames(s2c)\n",
       "     # [1] \"sample\"  \"genotype\"  \"drug\"  \"path\"\n",
       "     so <- sleuth_prep(s2c, ~genotype + drug)\n",
       "     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?sleuth_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_tx2gene_map = list(\"bos_taurus\"= \"/home//cmb-panasas2/skchoudh/genomes/bos_taurus/annotation/Bos_taurus.UMD3.1.94.tx2gene.tsv\",\n",
    "                       \"rattus_norvegicus\"=\"/home/cmb-panasas2/skchoudh/genomes/rattus_norvegicus/annotation/Rattus_norvegicus.Rnor_6.0.94.tx2gene.tsv\",\n",
    "                       \"pongo_abelii\"=\"/home/cmb-panasas2/skchoudh/genomes/pongo_abelii/annotation/Pongo_abelii.PPYG2.94.tx2gene.tsv\",\n",
    "                       \"monodelphis_domestica\"=\"/home/cmb-panasas2/skchoudh/genomes/monodelphis_domestica/annotation/Monodelphis_domestica.monDom5.94.tx2gene.tsv\",\n",
    "                       \"macaca_mulatta\"=\"/home/cmb-panasas2/skchoudh/genomes/macaca_mulatta/annotation/Macaca_mulatta.Mmul_8.0.1.94.tx2gene.tsv\",\n",
    "                       \"pan_troglodytes\" =\"/home/cmb-panasas2/skchoudh/genomes/pan_troglodytes/annotation/Pan_troglodytes.Pan_tro_3.0.94.tx2gene.tsv\",\n",
    "                       \"mus_musculus\"=\"/home/cmb-panasas2/skchoudh/genomes/mus_musculus/annotation/Mus_musculus.GRCm38.94.tx2gene.tsv\",\n",
    "                       \"homo_sapiens\" = \"/home/cmb-panasas2/skchoudh/genomes/homo_sapiens/annotation/Homo_sapiens.GRCh38.94.tx2gene.tsv\",\n",
    "                       \"gallus_gallus\" = \"/home/cmb-panasas2/skchoudh/genomes/gallus_gallus//annotation//Gallus_gallus.Gallus_gallus-5.0.94.tx2gene.tsv\",\n",
    "                       \"ornithorhynchus_anatinus\" = \"/home/cmb-panasas2/skchoudh/genomes/ornithorhynchus_anatinus/annotation/Ornithorhynchus_anatinus.OANA5.94.tx2gene.tsv\",\n",
    "                       \"gorilla_gorilla\" = \"/home/cmb-panasas2/skchoudh/genomes/gorilla_gorilla/annotation/Gorilla_gorilla.gorGor4.94.tx2gene.tsv\",\n",
    "                       \"pan_paniscus\" = \"/home/cmb-panasas2/skchoudh/genomes/pan_paniscus/annotation//Pan_paniscus.panpan1.1.94.tx2gene.tsv\"\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_to_gene <- function (species, srp, sampleInfo){\n",
    "    files <- file.path('/staging/as/skchoudh/rna-seq-output/', species, srp, '/counts/', sampleInfo$sample)\n",
    "    names(files) <- sampleInfo$tissue\n",
    "    print(species_tx2gene_map[[species]])\n",
    "    tx2gene <- read.table(species_tx2gene_map[[species]], header=FALSE)\n",
    "    txi.kallisto <- sle(files, type = \"kallisto\", ignoreTxVersion = TRUE, tx2gene = tx2gene)\n",
    "    df <- as.data.frame(txi.kallisto$counts)\n",
    "    #df$genes <- rownames(df)\n",
    "    write.table(df, file=file.path('/home//cmb-panasas2/skchoudh/github_projects/EE-546-project/cross-species-data/', paste0(srp, '-', species, '_kallisto_gene_tables.tsv')),  quote=F, sep='\\t', row.names=T, col.names=T)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"/home/cmb-panasas2/skchoudh/genomes/pan_troglodytes/annotation/Pan_troglodytes.Pan_tro_3.0.94.tx2gene.tsv\"\n"
     ]
    }
   ],
   "source": [
    "samples <- read.table('../cross-species-data/SRP136499_sample_info.tsv', header = TRUE, sep='\\t')\n",
    "species <- 'pan_troglodytes'\n",
    "srp <- 'SRP136499'\n",
    "sampleInfo<- samples[samples$species==species,]\n",
    "\n",
    "files <- file.path('/staging/as/skchoudh/rna-seq-output', species, srp, 'counts', sampleInfo$sample)\n",
    "sampleInfo$path <- files\n",
    "#names(files) <- sampleInfo$tissue\n",
    "print(species_tx2gene_map[[species]])\n",
    "t2g <- read.table(species_tx2gene_map[[species]], header=FALSE)\n",
    "colnames(t2g) <- c('target_id', 'gene_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading in kallisto results\n",
      "dropping unused factor levels\n",
      "................\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in check_target_mapping(tmp_names, target_mapping, !is.null(aggregation_column)): couldn't solve nonzero intersection\n",
     "execution_count": 23,
     "output_type": "error",
     "traceback": [
      "Error in check_target_mapping(tmp_names, target_mapping, !is.null(aggregation_column)): couldn't solve nonzero intersection\nTraceback:\n",
      "1. sleuth_prep(sampleInfo, extra_bootstrap_summary = TRUE, gene_level = TRUE, \n .     aggregation_column = \"gene_id\", target_mapping = t2g)",
      "2. check_target_mapping(tmp_names, target_mapping, !is.null(aggregation_column))",
      "3. stop(\"couldn't solve nonzero intersection\")"
     ]
    }
   ],
   "source": [
    "so <- sleuth_prep(sampleInfo, extra_bootstrap_summary = TRUE, gene_level=TRUE, aggregation_column='gene_id', target_mapping = t2g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/staging/as/skchoudh/rna-seq-output/pan_troglodytes/SRP136499/counts/SRX3849726'"
      ],
      "text/latex": [
       "'/staging/as/skchoudh/rna-seq-output/pan\\_troglodytes/SRP136499/counts/SRX3849726'"
      ],
      "text/markdown": [
       "'/staging/as/skchoudh/rna-seq-output/pan_troglodytes/SRP136499/counts/SRX3849726'"
      ],
      "text/plain": [
       "[1] \"/staging/as/skchoudh/rna-seq-output/pan_troglodytes/SRP136499/counts/SRX3849726\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampleInfo$path[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'so' not found\n",
     "execution_count": 24,
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'so' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "'/staging/as/skchoudh/rna-seq-output/pan_troglodytes/SRP136499/counts/SRX3849726/abundance.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'ENSPTRT00000000015.4'</li>\n",
       "\t<li>'ENSPTRT00000000017.4'</li>\n",
       "\t<li>'ENSPTRT00000000044.4'</li>\n",
       "\t<li>'ENSPTRT00000000050.4'</li>\n",
       "\t<li>'ENSPTRT00000000057.4'</li>\n",
       "\t<li>'ENSPTRT00000000060.3'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'ENSPTRT00000000015.4'\n",
       "\\item 'ENSPTRT00000000017.4'\n",
       "\\item 'ENSPTRT00000000044.4'\n",
       "\\item 'ENSPTRT00000000050.4'\n",
       "\\item 'ENSPTRT00000000057.4'\n",
       "\\item 'ENSPTRT00000000060.3'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'ENSPTRT00000000015.4'\n",
       "2. 'ENSPTRT00000000017.4'\n",
       "3. 'ENSPTRT00000000044.4'\n",
       "4. 'ENSPTRT00000000050.4'\n",
       "5. 'ENSPTRT00000000057.4'\n",
       "6. 'ENSPTRT00000000060.3'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"ENSPTRT00000000015.4\" \"ENSPTRT00000000017.4\" \"ENSPTRT00000000044.4\"\n",
       "[4] \"ENSPTRT00000000050.4\" \"ENSPTRT00000000057.4\" \"ENSPTRT00000000060.3\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_kal <- sleuth::read_kallisto('/staging/as/skchoudh/rna-seq-output/pan_troglodytes/SRP136499/counts/SRX3849726/abundance.tsv', read_bootstrap = F)\n",
    "head(test_kal$abundance$target_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\tkallisto object\n",
       "\n",
       "transcripts:  0 \n",
       "original number of transcripts:  0 \n",
       "Original or Subset:  Subsetbootstraps:  0 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_kal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R [conda env:scanpy_r]",
   "language": "R",
   "name": "conda-env-scanpy_r-r"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
